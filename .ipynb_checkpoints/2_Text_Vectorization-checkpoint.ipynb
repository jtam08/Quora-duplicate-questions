{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d19ac9-a64f-489e-a947-0a4317f03693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "from scipy.sparse import hstack\n",
    "import os , pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c7048f-f045-4404-abb9-01af2642cc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404287, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>...</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "\n",
       "                                           question2  is_duplicate  freq_qid1  \\\n",
       "0  what is the step by step guide to invest in sh...             0          1   \n",
       "1  what would happen if the indian government sto...             0          4   \n",
       "\n",
       "   freq_qid2  q1len  q2len  ...   ctc_max  last_word_eq  first_word_eq  \\\n",
       "0          1     66     57  ...  0.785709           0.0            1.0   \n",
       "1          2     51     88  ...  0.466664           0.0            1.0   \n",
       "\n",
       "   abs_len_diff  mean_len  token_set_ratio  token_sort_ratio  fuzz_ratio  \\\n",
       "0           2.0      13.0              100                93          93   \n",
       "1           5.0      12.5               86                63          66   \n",
       "\n",
       "   fuzz_partial_ratio  longest_substr_ratio  \n",
       "0                 100              0.982759  \n",
       "1                  75              0.596154  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_with_preprocess_2.csv\")\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac71c6a2-2dd9-4c9b-8288-3302e3404e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling 100k\n",
    "df = df.sample(n=100000,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84831346-834f-4d76-aa83-ccfc3bbd6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing columns to numeric type\n",
    "num_cols = df.drop(columns=['id', 'qid1', 'qid2', 'question1', 'question2']).columns\n",
    "for i in num_cols:\n",
    "    df[i] = df[i].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591dd589-bdd4-424f-9fb7-4e4137c60125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 28)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "y = df['is_duplicate']\n",
    "X = df[df.drop(columns=['id', 'qid1', 'qid2','is_duplicate']).columns.tolist()]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f208ec02-96a0-4997-ac5e-7f1968ebf053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data : (80000, 28)\n",
      "Number of data points in test data : (20000, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2,random_state=100)\n",
    "print(\"Number of data points in train data :\",X_train.shape)\n",
    "print(\"Number of data points in test data :\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74ca4c87-35b9-4dc8-9514-b87cc87d211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 20000)\n",
      "(20000, 20000)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer1 = TfidfVectorizer(lowercase=False,max_features= 20000)\n",
    "trainqs1_tfidf = tfidf_vectorizer1.fit_transform(X_train['question1'])\n",
    "testqs1_tfidf  = tfidf_vectorizer1.transform(X_test['question1'])\n",
    "print(trainqs1_tfidf.shape)\n",
    "print(testqs1_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296090b9-b46c-4e40-b07b-9594c6c73ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 20000)\n",
      "(20000, 20000)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer2 = TfidfVectorizer(lowercase=False,max_features= 20000)\n",
    "train_qs2_tfidf = tfidf_vectorizer2.fit_transform(X_train['question2'])\n",
    "test_qs2_tfidf  = tfidf_vectorizer2.transform(X_test['question2'])\n",
    "print(train_qs2_tfidf.shape)\n",
    "print(test_qs2_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1958aa91-9062-4e69-8939-9b9421f415dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (80000, 40000)\n",
      "Test data shape  (20000, 40000)\n"
     ]
    }
   ],
   "source": [
    "#Now we will hstack both the vectors\n",
    "tfidf_train_vec = hstack((trainqs1_tfidf,train_qs2_tfidf))\n",
    "tfidf_test_vec = hstack((testqs1_tfidf,test_qs2_tfidf)) \n",
    "print(\"train data shape\",tfidf_train_vec.shape)\n",
    "print(\"Test data shape \",tfidf_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cbb29cd-f468-47c6-acc6-d46d5863df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting other features\n",
    "train_df = X_train.drop(columns=['question1', 'question2'])\n",
    "test_df = X_test.drop(columns=['question1', 'question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0ce0fa-aeba-4122-bba4-e33a2b111a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to convert our data with features into sparse matrix so that we can combine our feature matrix and and tfidf vectors \n",
    "import scipy\n",
    "train_sparse = scipy.sparse.csr_matrix(train_df)\n",
    "test_sparse = scipy.sparse.csr_matrix(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3c75ac-e62c-496d-9ef3-dddb9051ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (80000, 40026)\n",
      "Test data shape  (20000, 40026)\n"
     ]
    }
   ],
   "source": [
    "# Now combining our tfidf and features into one \n",
    "tfidf_X_tr = hstack((train_sparse,tfidf_train_vec))\n",
    "tfidf_X_test = hstack((test_sparse,tfidf_test_vec))\n",
    "print(\"train data shape\",tfidf_X_tr.shape)\n",
    "print(\"Test data shape \",tfidf_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413734ae-ac36-4bf5-8a29-9071d2ac67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving tfidf vectors\n",
    "pickle.dump(tfidf_train_vec, open(\"tfidf_X_tr\",\"wb\"))\n",
    "pickle.dump(tfidf_test_vec, open(\"tfidf_X_test\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f66f07b4-b211-45b6-8ab3-0b3dc1863912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge texts\n",
    "questions = list(X_train['question1']) + list(X_train['question2'])\n",
    "tfidf = TfidfVectorizer(lowercase=False)\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ef748db-e288-4fd2-948d-07955be2b2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the spacy model that you have installed\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# each vector will be of length 94..\n",
    "doc = nlp(\"This is some text that I am processing with Spacy\")\n",
    "#example\n",
    "doc[3].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63abbb80-a535-45b2-92ff-f2128bbbc199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 80000/80000 [07:29<00:00, 178.17it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(X_train['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), 96])\n",
    "    for i,word1 in enumerate(doc1):\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1[i] += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "\n",
    "X_train_glove_q1 = vecs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6e1471e-a7c0-4763-92fc-6f782daa906b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 80000/80000 [15:01<00:00, 88.78it/s]    \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(X_train['question2'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), 96])\n",
    "    for i,word1 in enumerate(doc1):\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1[i] += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "\n",
    "X_train_glove_q2 = vecs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9d5e3fd-9882-4833-b921-62c74c7bc2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 20000/20000 [01:56<00:00, 171.69it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(X_test['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), 96])\n",
    "    for i,word1 in enumerate(doc1):\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1[i] += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "\n",
    "X_test_glove_q1 = vecs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5251db3-2134-42e0-9cae-563079a7f868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 20000/20000 [02:05<00:00, 159.97it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(X_test['question2'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), 96])\n",
    "    for i,word1 in enumerate(doc1):\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1[i] += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "\n",
    "X_test_glove_q2 = vecs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e052c94-cfaa-47e8-ad3a-9fa32261b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['q1_glove'] = X_train_glove_q1\n",
    "X_train['q2_glove'] = X_train_glove_q2\n",
    "X_test['q1_glove'] = X_test_glove_q1\n",
    "X_test['q2_glove'] = X_test_glove_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "922cc360-1dca-4b91-868a-4d38713e0bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 192)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_glove = np.concatenate([np.array(X_train_glove_q1),np.array(X_train_glove_q2)],axis=1)\n",
    "test_glove = np.concatenate([np.array(X_test_glove_q1),np.array(X_test_glove_q2)],axis=1)\n",
    "train_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74ca2be9-9e1b-468e-be15-13479657fbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g_0</th>\n",
       "      <th>g_1</th>\n",
       "      <th>g_2</th>\n",
       "      <th>g_3</th>\n",
       "      <th>g_4</th>\n",
       "      <th>g_5</th>\n",
       "      <th>g_6</th>\n",
       "      <th>g_7</th>\n",
       "      <th>g_8</th>\n",
       "      <th>g_9</th>\n",
       "      <th>...</th>\n",
       "      <th>g_182</th>\n",
       "      <th>g_183</th>\n",
       "      <th>g_184</th>\n",
       "      <th>g_185</th>\n",
       "      <th>g_186</th>\n",
       "      <th>g_187</th>\n",
       "      <th>g_188</th>\n",
       "      <th>g_189</th>\n",
       "      <th>g_190</th>\n",
       "      <th>g_191</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213359</td>\n",
       "      <td>1.404145</td>\n",
       "      <td>-0.522119</td>\n",
       "      <td>1.667424</td>\n",
       "      <td>3.190604</td>\n",
       "      <td>-0.613351</td>\n",
       "      <td>-1.231880</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.489607</td>\n",
       "      <td>1.027814</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.139855</td>\n",
       "      <td>-2.311613</td>\n",
       "      <td>1.795510</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>3.809993</td>\n",
       "      <td>1.407675</td>\n",
       "      <td>2.855578</td>\n",
       "      <td>0.525131</td>\n",
       "      <td>-0.346143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700429</td>\n",
       "      <td>2.836732</td>\n",
       "      <td>-0.245997</td>\n",
       "      <td>-0.092165</td>\n",
       "      <td>0.953189</td>\n",
       "      <td>0.496548</td>\n",
       "      <td>-2.625588</td>\n",
       "      <td>0.791676</td>\n",
       "      <td>-0.248484</td>\n",
       "      <td>1.900334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062467</td>\n",
       "      <td>-1.863858</td>\n",
       "      <td>1.871059</td>\n",
       "      <td>-1.406960</td>\n",
       "      <td>1.277069</td>\n",
       "      <td>2.936751</td>\n",
       "      <td>1.117216</td>\n",
       "      <td>0.947758</td>\n",
       "      <td>-0.979430</td>\n",
       "      <td>0.498250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.407290</td>\n",
       "      <td>0.897390</td>\n",
       "      <td>1.528612</td>\n",
       "      <td>1.700763</td>\n",
       "      <td>-1.223818</td>\n",
       "      <td>0.127207</td>\n",
       "      <td>-2.772973</td>\n",
       "      <td>-1.168565</td>\n",
       "      <td>0.653654</td>\n",
       "      <td>-0.701457</td>\n",
       "      <td>...</td>\n",
       "      <td>1.164281</td>\n",
       "      <td>-0.332287</td>\n",
       "      <td>-1.011394</td>\n",
       "      <td>0.965205</td>\n",
       "      <td>-1.284390</td>\n",
       "      <td>2.202049</td>\n",
       "      <td>0.376836</td>\n",
       "      <td>0.152748</td>\n",
       "      <td>0.743389</td>\n",
       "      <td>1.018471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.208959</td>\n",
       "      <td>2.236332</td>\n",
       "      <td>1.484938</td>\n",
       "      <td>-0.701985</td>\n",
       "      <td>3.068201</td>\n",
       "      <td>-0.851825</td>\n",
       "      <td>-0.749338</td>\n",
       "      <td>-1.357412</td>\n",
       "      <td>-0.446678</td>\n",
       "      <td>1.081915</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290982</td>\n",
       "      <td>-0.065734</td>\n",
       "      <td>-0.533942</td>\n",
       "      <td>1.010482</td>\n",
       "      <td>0.757438</td>\n",
       "      <td>1.942136</td>\n",
       "      <td>1.324279</td>\n",
       "      <td>-0.290915</td>\n",
       "      <td>-1.512556</td>\n",
       "      <td>-0.024621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.084556</td>\n",
       "      <td>5.075515</td>\n",
       "      <td>2.247029</td>\n",
       "      <td>-2.692966</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>1.428945</td>\n",
       "      <td>-4.528559</td>\n",
       "      <td>0.484562</td>\n",
       "      <td>1.144893</td>\n",
       "      <td>-0.113834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298600</td>\n",
       "      <td>-1.713485</td>\n",
       "      <td>0.889198</td>\n",
       "      <td>0.876387</td>\n",
       "      <td>-0.864238</td>\n",
       "      <td>1.263943</td>\n",
       "      <td>2.164503</td>\n",
       "      <td>0.762239</td>\n",
       "      <td>0.507218</td>\n",
       "      <td>-1.961154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        g_0       g_1       g_2       g_3       g_4       g_5       g_6  \\\n",
       "0  0.213359  1.404145 -0.522119  1.667424  3.190604 -0.613351 -1.231880   \n",
       "1  0.700429  2.836732 -0.245997 -0.092165  0.953189  0.496548 -2.625588   \n",
       "2  0.407290  0.897390  1.528612  1.700763 -1.223818  0.127207 -2.772973   \n",
       "3 -0.208959  2.236332  1.484938 -0.701985  3.068201 -0.851825 -0.749338   \n",
       "4  3.084556  5.075515  2.247029 -2.692966  0.828949  1.428945 -4.528559   \n",
       "\n",
       "        g_7       g_8       g_9  ...     g_182     g_183     g_184     g_185  \\\n",
       "0  0.094486 -0.489607  1.027814  ... -2.139855 -2.311613  1.795510  0.620619   \n",
       "1  0.791676 -0.248484  1.900334  ... -0.062467 -1.863858  1.871059 -1.406960   \n",
       "2 -1.168565  0.653654 -0.701457  ...  1.164281 -0.332287 -1.011394  0.965205   \n",
       "3 -1.357412 -0.446678  1.081915  ...  1.290982 -0.065734 -0.533942  1.010482   \n",
       "4  0.484562  1.144893 -0.113834  ... -0.298600 -1.713485  0.889198  0.876387   \n",
       "\n",
       "      g_186     g_187     g_188     g_189     g_190     g_191  \n",
       "0  0.553700  3.809993  1.407675  2.855578  0.525131 -0.346143  \n",
       "1  1.277069  2.936751  1.117216  0.947758 -0.979430  0.498250  \n",
       "2 -1.284390  2.202049  0.376836  0.152748  0.743389  1.018471  \n",
       "3  0.757438  1.942136  1.324279 -0.290915 -1.512556 -0.024621  \n",
       "4 -0.864238  1.263943  2.164503  0.762239  0.507218 -1.961154  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_train_df = pd.DataFrame(train_glove,columns=[f'g_{i}' for i in range(train_glove.shape[1])])\n",
    "glove_test_df = pd.DataFrame(test_glove,columns=[f'g_{i}' for i in range(test_glove.shape[1])])\n",
    "glove_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d481005d-97a1-4af2-8e3b-19af91566d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 28)\n",
      "(20000, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.drop(columns=['question1','question2']).reset_index(drop=True)\n",
    "X_test = X_test.drop(columns=['question1','question2']).reset_index(drop=True)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b640869f-e7a3-46ce-bc9f-9823ce10aac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 220)\n",
      "(20000, 220)\n"
     ]
    }
   ],
   "source": [
    "# concatenating\n",
    "X_train_d = pd.concat([X_train,glove_train_df],axis=1)\n",
    "X_test_d = pd.concat([X_test,glove_test_df],axis=1)\n",
    "print(X_train_d.shape)\n",
    "print(X_test_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c22e46f-9da3-41bf-8530-a4e43743ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d.to_csv('train_data.csv',index=False)\n",
    "X_test_d.to_csv('test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86833acd-acc5-4882-9ee5-0a4e06429788",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv('train_y.csv',index=False)\n",
    "y_test.to_csv('test_y.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2e75b-5da9-46af-9ceb-05da7b5b9ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
